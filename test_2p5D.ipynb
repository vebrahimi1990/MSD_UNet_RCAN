{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Input\n",
    "import matplotlib.pyplot as plt\n",
    "from tifffile import imwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_logical_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.LogicalDeviceConfiguration(memory_limit=12000)])\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Model_2D_UNet_RCAN, datagenerator_2p5D, Image_quality_assessment\n",
    "\n",
    "data_generator = datagenerator_2p5D.data_generator\n",
    "make_generator = Model_2D_UNet_RCAN.make_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_image_dr = r'D:\\Projects\\MSD_UNet_RCAN\\GT\\STED\\test\\STED.tif'\n",
    "wf_image_dr =r'D:\\Projects\\MSD_UNet_RCAN\\GT\\STED\\test\\Confocal.tif'\n",
    "lowSNR_image_dr =r'D:\\Projects\\MSD_UNet_RCAN\\GT\\Confocal\\test\\Average.tif'\n",
    "\n",
    "\n",
    "model_save_directory = r\"D:\\Projects\\MSD_UNet_RCAN\\GT\\Confocal\\confocal_1step.h5\" \n",
    "save_image_dr = r\"D:\\Projects\\MSD_UNet_RCAN\\GT\\Confocal\" \n",
    "save_parameters_dr = r\"D:\\Projects\\MSD_UNet_RCAN\\GT\\Confocal\\param.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2, 2048, 2048)\n",
      "[[0.         0.         0.00961318 ... 0.02883955 0.02883955 0.02883955]\n",
      " [0.00961318 0.         0.         ... 0.06730755 0.03846799 0.05769436]\n",
      " [0.         0.         0.         ... 0.06730755 0.00961318 0.01922637]\n",
      " ...\n",
      " [0.         0.         0.00961318 ... 0.06730755 0.07692073 0.07692073]\n",
      " [0.         0.         0.         ... 0.07692073 0.06730755 0.04808118]\n",
      " [0.         0.         0.         ... 0.13461509 0.07692073 0.10577554]]\n",
      "[[0.         0.         0.00925926 ... 0.0462963  0.02777778 0.0462963 ]\n",
      " [0.00925926 0.         0.         ... 0.03703704 0.0462963  0.01851852]\n",
      " [0.         0.         0.         ... 0.06481481 0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.00925926 ... 0.02777778 0.07407407 0.07407407]\n",
      " [0.         0.         0.         ... 0.12037037 0.06481481 0.05555556]\n",
      " [0.         0.         0.         ... 0.12962963 0.05555556 0.10185185]]\n",
      "6\n",
      "The training set shape is: (6, 2048, 2048, 1)\n",
      "The validation set shape is: (0, 2048, 2048, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 7, got 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m l_poisson1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[0;32m      6\u001b[0m l_poisson2\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m----> 8\u001b[0m x_test,w_test, y_test,_,_,_,wf \u001b[38;5;241m=\u001b[39m data_generator(GT_image_dr, lowSNR_image_dr,wf_image_dr, patch_size, n_patches,\n\u001b[0;32m      9\u001b[0m                                             n_channel\u001b[38;5;241m=\u001b[39mchannel_n, threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m,ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,lp1\u001b[38;5;241m=\u001b[39ml_poisson1,lp2\u001b[38;5;241m=\u001b[39ml_poisson2,\n\u001b[0;32m     10\u001b[0m                                              augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m                                              add_noise\u001b[38;5;241m=\u001b[39madd_noise)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 7, got 6)"
     ]
    }
   ],
   "source": [
    "patch_size =2048\n",
    "n_patches = 1\n",
    "channel_n =  0\n",
    "add_noise = True\n",
    "l_poisson1 = 0.01\n",
    "l_poisson2= 0.2\n",
    "\n",
    "x_test,w_test, y_test,_,_,_,wf = data_generator(GT_image_dr, lowSNR_image_dr,wf_image_dr, patch_size, n_patches,\n",
    "                                            n_channel=channel_n, threshold = 0.0,ratio=1.0,lp1=l_poisson1,lp2=l_poisson2,\n",
    "                                             augment=False, shuffle=False,\n",
    "                                             add_noise=add_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = np.random.randint(0,len(x_test),4)\n",
    "fig = plt.figure(figsize=(30,10))\n",
    "\n",
    "for i in range(4):\n",
    "    fig.add_subplot(2,6, 3*i+1)\n",
    "    cmap=plt.get_cmap('magma')\n",
    "    plt.imshow(x_test[ix[i],:,:,0].squeeze(),cmap)\n",
    "    plt.title('2.5D',fontdict={'fontsize':18})\n",
    "    plt_axis = plt.axis('off')\n",
    "    \n",
    "    fig.add_subplot(2,6, 3*i+2)\n",
    "    cmap=plt.get_cmap('magma')\n",
    "    plt.imshow(w_test[ix[i],:,:,0].squeeze(),cmap)\n",
    "    plt.title('MIP',fontdict={'fontsize':18})\n",
    "    plt_axis = plt.axis('off')\n",
    "    \n",
    "    fig.add_subplot(2,6, 3*i+3)\n",
    "    cmap=plt.get_cmap('magma')\n",
    "    plt.imshow(y_test[ix[i],:,:,0].squeeze(),cmap)\n",
    "    plt.title('Deconvolution',fontdict={'fontsize':18})\n",
    "    plt_axis = plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters =[32,64,128]\n",
    "\n",
    "num_filters = 64\n",
    "r = 16\n",
    "filters_cab=num_filters/r\n",
    "num_RG=5\n",
    "num_RCAB=5\n",
    "\n",
    "generator_input = Input((patch_size, patch_size,1))\n",
    "generator = make_generator(generator_input, filters, num_filters,filters_cab,num_RG,num_RCAB,\n",
    "                           kernel_shape=3,dropout=0.2)\n",
    "generator.load_weights(model_save_directory)\n",
    "\n",
    "prediction1 = np.zeros(x_test.shape)\n",
    "prediction2 = np.zeros(x_test.shape)\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    prediction= generator(x_test[i:i+1],training=False)\n",
    "    prediction1[i] = prediction['UNet']\n",
    "    prediction2[i] = prediction['RCAN']\n",
    "#     prediction1[i],prediction2[i]= generator(x_test[i:i+1],training=False)\n",
    "    prediction1[i] = prediction1[i]/prediction1[i].max()\n",
    "    prediction2[i] = prediction2[i]/prediction2[i].max()\n",
    "prediction1[prediction1<0]=0\n",
    "prediction2[prediction2<0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "Pl6pCBtNFOko",
    "outputId": "24ecab5f-9ec0-4bd7-8e1d-51ca3bbb8ed3"
   },
   "outputs": [],
   "source": [
    "ix = np.random.randint(len(prediction2))\n",
    "fig = plt.figure(figsize=(40,40))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(x_test[ix, :, :, 0] , cmap='magma')\n",
    "plt.title('Low SNR Input',fontdict={'fontsize':20})\n",
    "plt_axis = plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(prediction1[ix, :, :, 0] , cmap='magma')\n",
    "plt.title('Prediction by UNet',fontdict={'fontsize':20})\n",
    "plt_axis = plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(prediction2[ix, :, :, 0] , cmap='magma')\n",
    "plt.title('Prediction by RCAN',fontdict={'fontsize':20})\n",
    "plt_axis = plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(y_test[ix, :, :, 0] , cmap='magma')\n",
    "plt.title('Ground Truth',fontdict={'fontsize':20})\n",
    "plt_axis = plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gam = 1.2\n",
    "prediction2 = prediction2**(gam)\n",
    "for i in range(len(prediction2)):\n",
    "    prediction2[i] = prediction2[i]/prediction2[i].max()\n",
    "    \n",
    "# prediction1 = prediction1**(gam)\n",
    "# for i in range(len(prediction1)):\n",
    "#     prediction1[i] = prediction1[i]/prediction1[i].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "tJ-bKyN3iyfm",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def norm_mse(prediction, gt):\n",
    "    mse = tf.keras.metrics.mean_squared_error(prediction, gt)\n",
    "    mse = tf.math.reduce_sum(mse, axis=(1, 2))\n",
    "    norm = tf.norm(gt, axis=(1, 2))\n",
    "    norm = tf.squeeze(norm)\n",
    "    norm = tf.pow(norm, 2)\n",
    "    norm = tf.math.reduce_sum(norm)\n",
    "    norm_mse = tf.math.divide(mse, norm)\n",
    "    return norm_mse.numpy()\n",
    "\n",
    "def nmse_psnr_ssim(prediction,gt):\n",
    "    nmse = norm_mse(prediction,gt)\n",
    "    psnr = tf.image.psnr(prediction, gt, max_val = 1.0).numpy()\n",
    "    ssim = tf.image.ssim_multiscale(prediction, gt, max_val = 1.0, filter_size=14,\n",
    "                                    filter_sigma=1.5, k1=0.01, k2=0.03).numpy()\n",
    "    return nmse,psnr,ssim\n",
    "    \n",
    "imageq_param = np.zeros((9,len(prediction1)))\n",
    "\n",
    "imageq_param[0::3,:] = nmse_psnr_ssim(x_test,y_test)\n",
    "imageq_param[1::3,:] = nmse_psnr_ssim(prediction1,y_test)\n",
    "imageq_param[2::3,:] = nmse_psnr_ssim(prediction2,y_test)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "labels = ['noisy', 'prediction1', 'prediction2']\n",
    "\n",
    "bplot1 = axes[0].boxplot([imageq_param[0,:],imageq_param[1,:],imageq_param[2,:]],\n",
    "                         vert=True,  \n",
    "                         patch_artist=True,  \n",
    "                         labels=labels,showfliers=False)  \n",
    "axes[0].set_title('NMSE',fontsize=20)\n",
    "\n",
    "bplot2 = axes[1].boxplot([imageq_param[3,:],imageq_param[4,:],imageq_param[5,:]],\n",
    "                         vert=True,  \n",
    "                         patch_artist=True,  \n",
    "                         labels=labels,showfliers=False)  \n",
    "axes[1].set_title('PSNR',fontsize=20)\n",
    "\n",
    "bplot3 = axes[2].boxplot([imageq_param[6,:],imageq_param[7,:],imageq_param[8,:]],\n",
    "                         vert=True,  \n",
    "                         patch_artist=True,  \n",
    "                         labels=labels,showfliers=False)  \n",
    "cc= axes[2].set_title('MS-SSIM',fontsize=20)\n",
    "\n",
    "# np.savetxt(save_parameters_dr, np.transpose(imageq_param), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1_test = prediction1*(2**16-1)\n",
    "pred2_test = prediction2*(2**16-1)\n",
    "X_test = x_test*(2**16-1)\n",
    "Y_test = y_test*(2**16-1)\n",
    "\n",
    "pred1_test = pred1_test.astype(np.uint16)\n",
    "pred2_test = pred2_test.astype(np.uint16)\n",
    "X_test = X_test.astype(np.uint16)\n",
    "Y_test = Y_test.astype(np.uint16)\n",
    "\n",
    "imwrite(save_image_dr+'/pred1_2step_tub.tif', pred1_test.squeeze(),imagej=True,metadata={'axes': 'TYX'})\n",
    "imwrite(save_image_dr+'/pred2_2step_tub.tif', pred2_test.squeeze(),imagej=True,metadata={'axes': 'TYX'})\n",
    "imwrite(save_image_dr+'/noisy.tif', X_test.squeeze(),imagej=True,metadata={'axes': 'TYX'})\n",
    "imwrite(save_image_dr+'/gt.tif', Y_test.squeeze(),imagej=True,metadata={'axes': 'TYX'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Denoising_UNET_RCAN_3D.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
